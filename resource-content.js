// Resource content for the application

const resourceContent = {
    talking: `
### Syllabus Language Template

**Section: AI Use Policy**

This course recognizes AI tools as part of the contemporary learning landscape. Rather than blanket permission or prohibition, assignments in this course use **staged AI boundaries** that specify when and how AI can support your learning.

**Three types of AI boundaries you'll encounter:**

**üö´ No AI stages**: Some work must come entirely from your own observation, reading, creation, or experience. AI cannot reconstruct, enhance, or generate this foundational work. These stages protect the authenticity of primary engagement.

**ü§ù AI as Co-Intelligence stages**: After forming your own analysis, you may use AI to test interpretations, surface blind spots, or refine arguments. AI helps you think more rigorously but cannot replace your thinking. Specific productive and unproductive uses will be defined for each assignment.

**üõ†Ô∏è AI as Tool stages**: AI may be required for visualization, design, or communication tasks. You maintain authorship of ideas while using AI for implementation.

**Your responsibility**: Follow the AI boundaries specified for each assignment stage. Violating these boundaries is an academic integrity issue, not because AI use is inherently wrong, but because it circumvents the learning the assignment is designed to produce.

---

### First Day of Class Framing

**What to say**:

"I know many of you have strong feelings about AI‚Äîsome of you love using it, some are skeptical, some are confused about what's allowed. Here's my approach: I'm not interested in blanket rules because AI isn't one thing. It can be genuinely helpful for some tasks and genuinely harmful for others.

In this class, every assignment will tell you exactly when you can and can't use AI, and more importantly, **why**. The 'why' matters because I want you to develop judgment about when AI enhances your thinking versus when it replaces it.

Here's the pattern you'll see: First, I'll ask you to do something that requires your direct experience or observation‚ÄîAI can't do this for you because it wasn't there. Then, after you've formed your own interpretation, you can use AI as a thinking partner to test and refine your ideas. Finally, you might use AI as a communication tool.

If you ever wonder why a specific AI boundary exists, ask me. I can explain the pedagogical reasoning, and if you disagree, we can talk about it. But following these boundaries isn't optional‚Äîit's how the learning happens."

---

### Responding to Common Student Questions

**Student: "Why can't I use AI in Stage 1? It would make my writing better."**

**Faculty response**:
"I understand the impulse, but here's what would actually happen: AI would smooth over the specific, messy, sometimes awkward details that make your observation valuable. Those rough edges‚Äîmoments of confusion, surprising details you noticed, things that didn't fit your expectations‚Äîthat's the raw material for genuine analysis. If AI 'improves' Stage 1, you lose what makes your work worth analyzing in Stage 2. You're not avoiding AI because it's bad; you're avoiding it because you need authentic primary material to work with."

---

**Student: "How will you know if I used AI when I wasn't supposed to?"**

**Faculty response**:
"Honestly? Sometimes it's obvious‚ÄîAI has tells, like unnaturally polished writing disconnected from specific details, or analysis that could apply to anything rather than your specific situation. But here's what matters more: if you use AI in Stage 1, you won't have genuine material to work with in Stage 2. The assignment won't work for you. You'll struggle to write Stage 2 because you'll be trying to analyze something you didn't actually observe or experience. The constraint isn't there to catch cheaters‚Äîit's there because without it, you can't do the intellectual work the assignment requires."

---

**Student: "What if I'm just using AI to fix grammar or make sentences clearer?"**

**Faculty response**:
"Let's distinguish between two things: using AI as a proofreading tool versus using it to generate or substantially revise content. For Stage 1, I need your authentic observation in your authentic voice‚Äîincluding the roughness that comes from trying to capture something you actually witnessed. Grammar polishing can wait until Stage 2 or 3. If you're genuinely just fixing typos or adjusting sentence structure after you've written your observations, that's different from asking AI to 'improve' or 'enhance' your Stage 1 description. But if you're uncertain, write without AI first, then we can talk about what kinds of editing make sense."

---

**Student: "In Stage 2, how do I know if I've formed my interpretation 'enough' to use AI?"**

**Faculty response**:
"Good question. Here's a test: Before you engage AI, can you write out your interpretation in a few sentences without AI's help? If you can articulate your main claim and why you think it's true based on what you observed, then you're ready to use AI to stress-test it. If you're hoping AI will help you figure out what your interpretation should be, it's too early. The sequence matters: Observe (Stage 1) ‚Üí Interpret (Stage 2, on your own first) ‚Üí Test that interpretation (Stage 2, with AI) ‚Üí Refine and write (Stage 2, ongoing)."

---

**Student: "This seems really complicated. Why not just say 'no AI' or 'AI allowed'?"**

**Faculty response**:
"Because that's not how you'll use AI in your career. You're going to graduate into a world where AI is everywhere, and you'll need judgment about when to use it and when not to. Blanket rules don't teach judgment. This assignment structure gives you practice making those decisions with guidance. Think of it like learning to drive‚Äîat first, someone tells you exactly when to brake and accelerate, but eventually you develop the judgment to decide for yourself. These staged boundaries are the training wheels."
    `,

    workarounds: `
### What Faculty Have Seen & How to Address It

### Workaround 1: Using AI to "Remember" What They Observed

**What it looks like**:
Student observes an organizational meeting but doesn't take detailed notes. Later, they describe the meeting to ChatGPT and ask it to "help reconstruct" what happened or "fill in details I might have missed."

**Why students do this**:
They didn't realize they needed to document thoroughly during the observation, or they think AI is just helping them "remember better."

**The harm**:
AI doesn't reconstruct memory‚Äîit generates plausible content based on patterns. The student ends up with AI-generated organizational behavior that sounds realistic but didn't actually happen. They lose their specific, authentic observation.

**How to address it**:
**Prevention**: In Stage 1 instructions, be explicit: "Take detailed notes during your observation. You cannot use AI later to reconstruct or fill in details you didn't document. If you missed something, acknowledge the gap rather than inventing content."

**If you catch it**: "I can tell this observation has been AI-enhanced because it's too polished and generic. Real observations include gaps, uncertainties, and specific odd details. Let's talk about what you actually remember without AI's help, even if it's less complete."

---

### Workaround 2: Asking AI to Analyze Stage 1 Content Before Forming Their Own Interpretation

**What it looks like**:
Student completes Stage 1 authentically, then immediately pastes it into ChatGPT and asks: "Analyze this organizational meeting using concepts from *Same As Ever*" or "What themes emerge from this field observation?"

**Why students do this**:
They're overwhelmed by the open-ended nature of interpretation and want guidance on "what it means" before committing to an interpretation.

**The harm**:
The student skips the most important cognitive work‚Äîwrestling with their observations to form their own interpretation. They end up defending AI's interpretation rather than developing their own analytical thinking.

**How to address it**:
**Prevention**: In Stage 2 instructions, state explicitly: "Before engaging AI, write out your interpretation in your own words. What do you think your Stage 1 observations reveal? Only after you can articulate this should you use AI to test your interpretation."

**If you catch it**: "Your Stage 2 analysis reads like you started with AI's interpretation rather than your own. Here's what I want you to do: Write me three sentences explaining what you think your observations reveal, without looking at any AI output. Once you've done that, we can talk about how AI might help strengthen that interpretation."

---

### Workaround 3: Using AI to Generate "Original" Observations Based on Theory

**What it looks like**:
Student asks ChatGPT: "Describe an organizational meeting that would illustrate short-term thinking and risk aversion" and then writes up that AI-generated scenario as their Stage 1 "observation."

**Why students do this**:
They don't have access to an appropriate observation, didn't plan ahead, or don't understand that fabricated observations undermine the entire assignment.

**The harm**:
The entire assignment collapses. Without authentic observation, there's nothing genuine to analyze. The student is essentially writing fan fiction about organizational behavior rather than learning to analyze real human dynamics.

**How to address it**:
**Prevention**: Be clear in instructions: "If you're struggling to find an appropriate situation to observe, come talk to me. We can identify alternatives together. Do not fabricate observations or use AI to create hypothetical scenarios."

**If you catch it**: "This observation doesn't read like something you personally witnessed‚Äîit reads like an illustration of theory. Tell me about the actual situation you observed, including the parts that were confusing or didn't fit the theory neatly. That's what makes observation valuable."

---

### Workaround 4: Having AI Write the Co-Intelligence Appendix

**What it looks like**:
Student asks ChatGPT: "Write a reflection on where AI helped and where it missed nuance in analyzing organizational behavior."

**Why students do this**:
They view the appendix as just another required paragraph rather than genuine metacognitive reflection. Or they didn't actually use AI productively and don't know what to write.

**The harm**:
You lose the diagnostic information the appendix is designed to provide‚Äîevidence of whether the student actually engaged AI thoughtfully.

**How to address it**:
**Prevention**: Frame the appendix as: "This is where you tell me honestly how AI did or didn't help you think. I'm not grading whether AI was useful‚ÄîI'm grading whether you can reflect on its role. If AI wasn't helpful, say that and explain why."

**If you catch it**: Generic appendices are usually the tell: "AI helped me consider multiple perspectives and think more deeply." Real reflections are specific: "AI suggested the conflict was about resource allocation, but it missed that the real issue was distrust between the president and treasurer, which I could see in their body language."

---

### Workaround 5: Using AI for Stage 1 but Claiming They Didn't

**What it looks like**:
When confronted about suspiciously polished or generic Stage 1 work, student insists they didn't use AI.

**Why students do this**:
Fear of consequences, or genuine confusion about what "counts" as AI use (did grammar checking cross the line?).

**The harm**:
Creates an adversarial dynamic and prevents learning from the mistake.

**How to address it**:
**Prevention**: Create a low-stakes "AI use checkpoint" early in the assignment. After Stage 1 draft, have students submit a brief note: "Did you use AI for any part of Stage 1? If yes, describe how." Make it clear this is diagnostic, not punitive. This creates an opportunity for correction before the final submission.

**If it happens**: "I'm less concerned about whether you used AI than about why your Stage 1 work doesn't have the characteristics I'd expect from authentic observation. Let's talk about what happened. If you used AI unintentionally or weren't sure about the boundaries, we can figure out how to revise. But I need you to be honest with me about your process."

---

### General Prevention Strategy

**Build in a mid-point check-in**: After Stage 1 is complete but before Stage 2 begins, have a brief conference, peer review, or online check-in where students share their observations. This creates accountability and lets you catch problems early.

**Make the "why" visible**: Students are less likely to circumvent boundaries they understand. Regularly explain why each constraint exists and what learning it protects.

**Create a revision path**: If students realize they violated boundaries, let them revise with a minor penalty. This reduces the incentive to lie and creates a learning opportunity.
    `,

    adapting: `
### Quick Guides for Common Assignment Formats

### Laboratory Reports (Sciences)

**Stage 1: Experimental Work (No AI)**
Students conduct experiments, record observations, collect data. AI cannot generate hypothetical results, "clean up" messy data, or simulate experiments not performed.

**Why no AI**: Laboratory skills require distinguishing between what actually happened versus what should have happened according to theory. AI would generate idealized results that obscure experimental realities.

**Deliverable**: Lab notebook with raw data, observations, procedural notes

---

**Stage 2: Analysis and Interpretation (AI as Co-Intelligence)**
Students analyze data, identify patterns, connect findings to theory. AI can help with statistical interpretation, suggesting alternative explanations for results, or identifying confounding variables.

**Productive AI use**: "My data shows X, but theory predicts Y. What factors might explain this discrepancy?" or "Help me check if my statistical approach is appropriate for this data type."

**Unproductive AI use**: Having AI generate the discussion section from raw data, asking AI to explain results without student's initial interpretation.

**Deliverable**: Analysis section with interpretation of findings

---

**Stage 3: Implications and Further Research (AI as Co-Intelligence)**
Students propose follow-up experiments or explain real-world applications. AI can help identify relevant literature or refine experimental design proposals.

**Deliverable**: Discussion and conclusions section

---

### Problem Sets (Mathematics, Physics, Engineering)

**Stage 1: Individual Problem Solving (No AI)**
Students attempt problems using course concepts. AI cannot solve problems, check work, or suggest approaches.

**Why no AI**: Problem-solving skills develop through struggle. AI eliminates the productive difficulty that builds mathematical thinking.

**Deliverable**: Initial problem attempts showing work

---

**Stage 2: Solution Refinement (AI as Co-Intelligence)**
After attempting problems independently, students can use AI to check their approach (not their answer), identify conceptual errors, or understand why a method failed.

**Productive AI use**: "I tried solving this differential equation using separation of variables, but got stuck at this step. What's wrong with my approach?" (without showing AI the full solution)

**Unproductive AI use**: "Solve this problem for me" or "Check if my answer is correct" without first attempting it.

**Deliverable**: Revised solutions with reflection on errors

---

**Stage 3: Concept Application (AI as Tool)**
Students create new problems or explain concepts to others. AI can help generate visualizations or check that their created problems are solvable.

**Deliverable**: Original problems with solutions, or explanatory materials

---

### Creative Projects (Art, Music, Creative Writing)

**Stage 1: Initial Creation (No AI)**
Students produce original work‚Äîsketches, compositions, drafts. AI cannot generate ideas, create content, or suggest creative directions.

**Why no AI**: Creative development requires authentic exploration of materials, forms, and personal expression. AI shortcuts eliminate the discovery process.

**Deliverable**: Multiple drafts, sketches, or iterations showing creative process

---

**Stage 2: Conceptual Reflection (AI as Co-Intelligence)**
Students articulate what their work is exploring or achieving. AI can help refine language, suggest art historical context, or test whether their artist statement accurately describes what's visible in the work.

**Productive AI use**: "I'm trying to articulate how my use of repetition creates tension. Does this statement capture what's happening in the work, or am I describing something that's not actually visible?"

**Unproductive AI use**: Having AI generate an artist statement or explain what the work "means."

**Deliverable**: Artist statement and conceptual analysis

---

**Stage 3: Series Extension or Presentation (AI as Tool)**
Students design how work would be exhibited, or create next iterations. AI can help visualize installation layouts or generate mockups.

**Deliverable**: Installation plan or series proposal

---

### Presentations (Any Discipline)

**Stage 1: Content Development (No AI)**
Students research, analyze, and form arguments. AI cannot generate slide content or write talking points.

**Why no AI**: The thinking that makes a presentation compelling must come from the student's own engagement with material.

**Deliverable**: Presentation outline with key arguments

---

**Stage 2: Argument Refinement (AI as Co-Intelligence)**
Students use AI to test whether their explanation is clear, identify missing context, or strengthen transitions between ideas.

**Productive AI use**: "I'm explaining this concept to an audience unfamiliar with the field. Does my explanation assume too much prior knowledge?"

**Unproductive AI use**: Having AI write slides or generate presenter notes from an outline.

**Deliverable**: Draft presentation

---

**Stage 3: Design and Delivery (AI as Tool)**
Students use AI to create visuals, suggest design improvements, or practice delivery. AI can generate slide templates or help format complex data visualizations.

**Deliverable**: Final presentation

---

### General Adaptation Principles

1. **Identify the core learning objective**: What skill or thinking do you most want students to develop? Protect that with Stage 1 constraints.

2. **Recognize where AI genuinely helps**: Once students have formed their own thinking, AI can strengthen it through critique, refinement, or helping identify gaps.

3. **Allow AI for implementation**: If the learning goal is insight (not technical execution), AI can support the communication or implementation of that insight.

4. **Make boundaries explicit**: Don't assume students will infer appropriate use. Spell out what's productive vs. unproductive for your specific assignment type.
    `,

    assessment: `
### Evaluating Productive vs. Unproductive AI Use

### Stage 1: Authentic Primary Work

**Excellent (A range)**
- Work demonstrates direct, unmediated engagement with source material
- Includes specific, concrete details that could only come from personal observation/experience
- Shows evidence of authentic noticing‚Äîincluding surprising, confusing, or unexpected elements
- Contains appropriate gaps or uncertainties (acknowledges what wasn't observed rather than fabricating)
- Voice and style reflect genuine documentation rather than polished prose

**Proficient (B range)**
- Work shows genuine engagement with source material
- Includes specific details, though may occasionally slip into generalizations
- Mostly captures authentic observation with minimal AI-enhanced smoothing
- Generally maintains documentary voice

**Developing (C range)**
- Work contains mix of authentic observation and generic or theoretical description
- Lacks specific concrete details; could describe many similar situations
- May be overly polished for Stage 1 documentation
- Shows signs of AI reconstruction or enhancement

**Needs Revision (D/F range)**
- Work appears to be AI-generated hypothetical scenario rather than authentic observation
- Contains only generic details that could apply to any situation
- Lacks the specificity, messiness, or uncertainty characteristic of real observation
- May directly contradict claim to have personally witnessed events

---

### Stage 2: Conceptual Interpretation with AI Co-Intelligence

**Excellent (A range)**
- Interpretation is clearly grounded in specific Stage 1 observations
- Analysis reveals original thinking that connects observations to concepts in novel ways
- Shows evidence of using AI to stress-test interpretation (acknowledges alternative explanations considered)
- Demonstrates that AI enhanced but didn't replace analytical thinking
- Makes specific, defensible claims supported by observational evidence
- Co-Intelligence Appendix shows sophisticated understanding of where AI helped vs. where human judgment was essential

**Proficient (B range)**
- Interpretation connects Stage 1 observations to conceptual frameworks appropriately
- Shows some original analytical thinking with AI support
- Makes reasonable claims supported by evidence
- Co-Intelligence Appendix shows awareness of AI's role

**Developing (C range)**
- Interpretation feels somewhat disconnected from specific Stage 1 observations
- Analysis may rely heavily on AI-generated insights with insufficient student development
- Claims are generic rather than specific to the student's situation
- Co-Intelligence Appendix is formulaic or vague

**Needs Revision (D/F range)**
- Interpretation appears to be AI-generated from Stage 1 content with minimal student contribution
- Generic analysis that could apply to any situation, not grounded in student's specific observations
- Shows little evidence of student's own analytical thinking
- Co-Intelligence Appendix is missing, perfunctory, or appears AI-generated itself

---

### Diagnostic Questions for Evaluating Stage 2

When reading Stage 2 analysis, ask yourself:

**Did the student form this interpretation, or did AI?**
- Look for: Specific connections to their unique Stage 1 observations, acknowledgment of alternative interpretations, discussion of what doesn't fit the framework
- Red flags: Generic analysis, perfect theoretical fit with no acknowledgment of ambiguity, disconnection from specific Stage 1 details

**Can you see evidence of revision based on critical thinking?**
- Look for: Places where the student acknowledges initial interpretation was insufficient, discusses factors they initially underweighted, shows refinement of thinking
- Red flags: Perfectly formed argument with no signs of evolution or testing

**Does the Co-Intelligence Appendix ring true?**
- Look for: Specific examples of how AI helped or failed, honest assessment of limitations, connection to actual analytical work
- Red flags: Generic statements ("AI helped me think more deeply"), no specific examples, unrealistically positive assessment of AI's contribution

---

### Sample Rubric Language for Syllabi

**Criterion: Appropriate AI Use in Analysis (Stage 2)**

**Exemplary**: Student demonstrates independent formation of interpretation before engaging AI, uses AI strategically to test and refine thinking, shows evidence of critical engagement with AI suggestions rather than uncritical acceptance, and provides thoughtful reflection on AI's contributions and limitations in the Co-Intelligence Appendix.

**Proficient**: Student forms own interpretation and uses AI to support refinement, shows reasonable critical engagement with AI suggestions, and provides adequate reflection on AI's role.

**Developing**: Student may have relied too heavily on AI to generate interpretation, shows limited critical engagement with AI suggestions, or provides superficial reflection on AI's role.

**Unsatisfactory**: Student appears to have outsourced interpretation to AI, shows no evidence of independent analytical thinking, or fails to reflect on AI use meaningfully.

---

### Feedback Templates

**When AI use is productive**:
"Your Stage 2 analysis shows effective use of AI as co-intelligence. I can see you formed your initial interpretation [cite specific example], then used AI to consider [alternative explanation you discussed]. This strengthened your argument by [specific improvement]. Your Co-Intelligence Appendix honestly acknowledges where AI helped with [X] but couldn't capture [Y]."

---

**When AI use needs improvement**:
"Your Stage 2 analysis suggests you may have engaged AI before fully forming your own interpretation. The analysis feels disconnected from your specific Stage 1 observations‚Äînotice how [specific paragraph] could apply to any organizational meeting, not just the one you witnessed. For revision, I'd like you to first write out in your own words what you think your observations reveal, without AI assistance. Only then use AI to test that interpretation."

---

**When AI use appears to have replaced thinking**:
"Your Stage 2 reads like AI-generated analysis rather than your own interpretation supported by AI. The telltale signs are [overly polished prose disconnected from specific details / generic theoretical explanation / perfect fit to framework with no acknowledgment of what doesn't fit]. The Co-Intelligence Appendix also doesn't ring true because [generic rather than specific / no real examples of AI interaction / unrealistically positive assessment]. I need to see your thinking process. Let's meet to discuss how you actually developed this analysis."

---

### Assessment Philosophy Statement (for faculty)

The goal of evaluating AI co-intelligence use isn't to catch students cheating‚Äîit's to assess whether they're developing the judgment to use AI productively. This means:

1. **Transparency is rewarded**: Students who honestly acknowledge AI limitations or missteps in the appendix should be viewed favorably, even if their analysis isn't perfect.

2. **Process matters as much as product**: Evidence of revision, wrestling with ideas, and testing interpretations counts significantly, even if the final argument isn't the strongest possible.

3. **Violations are teaching moments**: When students cross boundaries inappropriately, the goal is to help them understand why the boundary exists and how to use AI better, not just to penalize.

4. **Assessment should mirror the learning goal**: If the goal is developing analytical judgment, assess analytical judgment‚Äînot just whether rules were followed.
    `
};
